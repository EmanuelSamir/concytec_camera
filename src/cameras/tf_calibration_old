#!/usr/bin/env python
# -*- coding: utf-8 -*-
import numpy as np
import rospy, tf, math, copy, sys
from ar_track_alvar_msgs.msg import AlvarMarkers
from tf.transformations import quaternion_matrix, quaternion_from_matrix

def pose2mat(pose):
    """
    Converts pose np.array([[x],[y],[qw],[qx],[qy],[qz]]) into matrix.
    Could work also with 1-D array or list.
    """
    T = quaternion_matrix(pose[3:])
    T[:3,3] = np.array(pose[:3])
    return T

def mat2pose(m):
    """
    Converts numpy matrix (4x4) into pose np.array([[x],[y],[qw],[qx],[qy],[qz]])
    """
    q = np.expand_dims(quaternion_from_matrix(m), axis=1)
    p = np.expand_dims(m[:3,3], axis=1)
    pose = np.vstack((p,q))
    return pose

def T_inv(T_in):
    """
    Calculates the inverse of a Transformation Matrix (4x4).
    """
    R_in = T_in[:3,:3]
    t_in = T_in[:3,[-1]]
    R_out = R_in.T
    t_out = -np.matmul(R_out,t_in)
    return np.vstack((np.hstack((R_out,t_out)),np.array([0, 0, 0, 1])))

class ArTagTracker:
    def __init__(self, camera_ns):
        """
        Class to get artag poses for a camera.
        Args: camera_ns:= Camera namespace group (e.g. /camera_1)
        """
        self.poses = dict()
        artag_pose_topic = camera_ns + '/ar_pose_marker'
        rospy.Subscriber(artag_pose_topic, AlvarMarkers, self.callback)

    def callback(self, msg):
        tag_ids = []
        poses = []
        for marker in msg.markers:
            tag_ids.append(marker.id) 
            o = marker.pose.pose.orientation
            p = marker.pose.pose.position
            poses.append(np.array([p.x, p.y, p.z, o.x, o.y, o.z, o.w]))
        self.poses = dict(zip(tag_ids, poses))

class KalmanConstantEstimator:
    """
    Class to estimate a constant value from noisy signals. Made adhoc for a (7,1) pose vector
    Kalman Estimator based on
    http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/WELCH/kalman.3.html
    """
    def __init__(self, x0):
        n = 7
        self.Q = 1e-5*np.eye(n) # Process variance
        self.R = 0.2*np.eye(n)  # Measurement variance

        self.x_t   = x0
        self.x_t_1 = np.zeros((n,1))

        self.K     = 0.1*np.ones((n,n))
        self.P_t   = 1.0*np.ones((n,n))
        self.P_t_1 = np.zeros((n,n))

        self.train = []
        
    def prediction(self):
        self.x_t_1 = copy.copy(self.x_t)
        self.P_t_1 = copy.copy(self.P_t) + self.Q
        
    def correction(self, z):
        self.K = self.P_t_1 * np.linalg.pinv(self.P_t_1 + self.R)
        self.x_t = self.x_t_1 + np.dot(self.K, (z - self.x_t_1))
        self.P_t = np.dot((np.eye(7) - self.K), self.P_t_1)

    def flag_stable(self):
        """
        Additional function that is constantly checking that state x_t holds
        as constant for a defined N_train length using standard desviation.
        Used for calibration. Smaller e, more precision of the calibrator.
        """
        N_train = 50
        flag = False
        e = 1e-3

        if len(self.train) < N_train:
            self.train.append(np.linalg.norm(self.x_t))
        else:
            self.train = self.train[1:]
            self.train.append(np.linalg.norm(self.x_t))
            x = np.std(self.train)
            if x < e:
                flag = True

        return flag

def calibration_process():
    tracker_camera1 = ArTagTracker('/camera1')
    tracker_camera2 = ArTagTracker('/camera2')
    rate = rospy.Rate(20)

    ID_TMP = 0
    ID_1 = 1

    # Calibration T1 -> T2
    rospy.loginfo("Colocar tag tmp visible para camaras 1 y 2")
    _ = raw_input("Press Enter to continue...")

    while True:
        rate.sleep()
        if (ID_TMP in tracker_camera1.poses) and (ID_TMP in tracker_camera2.poses):
            break
        if rospy.is_shutdown():
            rospy.loginfo("Out because of ctrl + c.")
            sys.exit(0)

    rospy.loginfo("Tag tmp encontrado. Inicio de calibracion T1 -> T2.")

    # Initialize pose vector
    p_1_2 = np.zeros((7,1))
    filt_1_2 = KalmanConstantEstimator(p_1_2)

    while True: 
        if not (ID_TMP in tracker_camera1.poses) or not (ID_TMP in tracker_camera2.poses) or rospy.is_shutdown() :
            rospy.loginfo("Out because of ctrl + c or cameras were not located correctly.")
            sys.exit(0)

        p_1_tmp = tracker_camera1.poses[ID_TMP]
        p_2_tmp = tracker_camera2.poses[ID_TMP]

        T_1_tmp = pose2mat(p_1_tmp)
        T_2_tmp = pose2mat(p_2_tmp)
        
        T_tmp_2 = T_inv(T_2_tmp)
        T_1_2 = T_1_tmp.dot(T_tmp_2)

        p_1_2 = mat2pose(T_1_2)

        filt_1_2.prediction()
        filt_1_2.correction(p_1_2)

        flag = filt_1_2.flag_stable()

        if flag:
            rospy.loginfo("Calibration was correct for T1 -> T2")
            break
        rate.sleep()

    rospy.loginfo("Starting calibration T0->T1")

    # Calibration T0 -> T1
    rospy.loginfo("Colocar tag 1 visible para camara 1")
    _ = raw_input("Press Enter to continue...")

    while True:
        rate.sleep()
        if (ID_1 in tracker_camera1.poses):
            break
        if rospy.is_shutdown():
            rospy.loginfo("Out because of ctrl + c.")
            sys.exit(0)

    rospy.loginfo("Tag 1 encontrado. Inicio de calibracion T0 -> T1.")
    # Initialize pose vector
    p_0_1 = np.zeros((7,1))
    filt_0_1 = KalmanConstantEstimator(p_0_1)

    while True: 
        if not (ID_1 in tracker_camera1.poses) or rospy.is_shutdown() :
            rospy.loginfo("Out because of ctrl + c or cameras were not located correctly.")
            sys.exit(0)

        p_1_0 = tracker_camera1.poses[ID_1]
        T_1_0 = pose2mat(p_1_0)
        
        T_0_1 = T_inv(T_1_0)

        p_0_1 = mat2pose(T_0_1)

        filt_0_1.prediction()
        filt_0_1.correction(p_0_1)

        flag = filt_0_1.flag_stable()

        if flag:
            rospy.loginfo("Calibration was correct for T0 -> T1")
            break
        rate.sleep()

    T_0_1 = pose2mat(np.squeeze(filt_0_1.x_t))
    T_1_2 = pose2mat(np.squeeze(filt_1_2.x_t))

    T_0_2 = T_0_1.dot(T_1_2)
    
    return T_0_1, T_0_2


def main():
    # Node definition
    rospy.init_node("tf_calibration", anonymous=True)
    rate = rospy.Rate(20)

    use_saved_data = rospy.get_param('/tf_calibration/use_saved_data')
    tf_path = rospy.get_param('/tf_calibration/tf_config')

    if use_saved_data:
        rospy.loginfo('Calibrating ... ')
        (T_0_1, T_0_2) = calibration_process()

        rospy.loginfo('Saving tf ...')

        with open(tf_path + '/t01', 'wb') as f:
            np.save(f, T_0_1)

        with open(tf_path + '/t02', 'wb') as f:
            np.save(f, T_0_2)
    else:
        rospy.loginfo('Using saved data instead of calibration')
        with open(tf_path + '/t01', 'rb') as f:
            T_0_1 = np.load(f)

        with open(tf_path + '/t02', 'rb') as f:
            T_0_2 = np.load(f)

    rospy.loginfo('tf ready for broadcasting ...')

    # Broadcasting tf 
    tf_0_1 = mat2pose(T_0_1)
    tf_0_2 = mat2pose(T_0_2)

    rospy.loginfo('tf are broadcasted successfully')
    
    while not rospy.is_shutdown():
        broadcaster01 = tf.TransformBroadcaster()
        broadcaster01.sendTransform(
                            (tf_0_1[0], tf_0_1[1], tf_0_1[2]),
                            (tf_0_1[3], tf_0_1[4], tf_0_1[5], tf_0_1[6]),
                            rospy.Time.now(),
                            "camera1",
                            "world")

        broadcaster02 = tf.TransformBroadcaster()
        broadcaster02.sendTransform(
                            (tf_0_2[0], tf_0_2[1], tf_0_2[2]),
                            (tf_0_2[3], tf_0_2[4], tf_0_2[5], tf_0_2[6]),
                            rospy.Time.now(),
                            "camera2",
                            "world")
        rate.sleep()

if __name__ == '__main__':
    main()